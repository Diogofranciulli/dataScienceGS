# Sistema de Monitoramento de Queimadas na Amaz√¥nia
# An√°lise de Dados Hist√≥ricos de Inc√™ndios Florestais

import pandas as pd
import numpy as np
import matplotlib

# Configurar matplotlib para n√£o usar interface gr√°fica
matplotlib.use('Agg')  # Usar backend n√£o-interativo
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import warnings

warnings.filterwarnings('ignore')

plt.style.use('seaborn-v0_8')
sns.set_palette("husl")


class AmazonFireAnalyzer:
    def __init__(self):
        self.data = None
        self.processed_data = None

    def generate_sample_data(self):
        np.random.seed(42)

        start_date = datetime(2021, 1, 1)
        end_date = datetime(2024, 12, 31)
        dates = pd.date_range(start=start_date, end=end_date, freq='D')

        n_records = len(dates) * 15

        amazon_states = ['Acre', 'Amazonas', 'Amap√°', 'Maranh√£o', 'Mato Grosso',
                         'Par√°', 'Rond√¥nia', 'Roraima', 'Tocantins']
        causes = ['Humana', 'Natural', 'Desconhecida']
        cause_weights = [0.7, 0.2, 0.1]

        data = []
        for _ in range(n_records):
            date = np.random.choice(dates)
            if isinstance(date, np.datetime64):
                date = pd.to_datetime(date).to_pydatetime()
            month = date.month
            seasonal_factor = 2.5 if 5 <= month <= 10 else 0.5

            if np.random.random() > (0.3 * seasonal_factor):
                continue

            state = np.random.choice(amazon_states)
            cause = np.random.choice(causes, p=cause_weights)

            if cause == 'Humana':
                size_ha = np.random.lognormal(2, 1.5) * seasonal_factor
            else:
                size_ha = np.random.lognormal(1.5, 1.2) * seasonal_factor

            if size_ha < 10:
                size_class = 'Pequeno'
            elif size_ha < 100:
                size_class = 'M√©dio'
            elif size_ha < 1000:
                size_class = 'Grande'
            else:
                size_class = 'Muito Grande'

            lat = np.random.uniform(-10, 5)
            lon = np.random.uniform(-75, -45)

            data.append({
                'data': date,
                'estado': state,
                'causa': cause,
                'tamanho_ha': round(size_ha, 2),
                'classificacao_tamanho': size_class,
                'latitude': round(lat, 4),
                'longitude': round(lon, 4),
                'mes': month,
                'ano': date.year,
                'estacao_seca': month in [5, 6, 7, 8, 9, 10]
            })

        self.data = pd.DataFrame(data)
        print(f"Dataset gerado com {len(self.data)} registros de inc√™ndios")
        return self.data

    def clean_and_process_data(self):
        if self.data is None:
            self.generate_sample_data()

        initial_count = len(self.data)
        self.data = self.data.drop_duplicates()
        duplicates_removed = initial_count - len(self.data)

        self.data['estado'] = self.data['estado'].str.strip()
        self.data['causa'] = self.data['causa'].str.strip()

        self.data = self.data.dropna()

        q99 = self.data['tamanho_ha'].quantile(0.99)
        outliers_removed = len(self.data[self.data['tamanho_ha'] > q99])
        self.data = self.data[self.data['tamanho_ha'] <= q99]

        self.processed_data = self.data.copy()

        print(f"Duplicatas removidas: {duplicates_removed}")
        print(f"Outliers removidos: {outliers_removed}")
        print(f"Total ap√≥s limpeza: {len(self.processed_data)} registros")

    def descriptive_analysis(self):
        if self.processed_data is None:
            self.clean_and_process_data()

        total_fires = len(self.processed_data)
        total_area = self.processed_data['tamanho_ha'].sum()

        print(f"\nTotal de inc√™ndios: {total_fires}")
        print(f"√Årea total queimada: {total_area:.2f} ha")

        yearly = self.processed_data.groupby('ano').agg(
            Numero_Inc√™ndios=('data', 'count'),
            √Årea_Total_ha=('tamanho_ha', 'sum'),
            Tamanho_M√©dio_ha=('tamanho_ha', 'mean')
        )
        print("\nResumo anual:\n", yearly)

        causes = self.processed_data.groupby('causa').agg(
            Frequ√™ncia=('data', 'count'),
            √Årea_Total_ha=('tamanho_ha', 'sum'),
            Tamanho_M√©dio_ha=('tamanho_ha', 'mean')
        )
        print("\nPor causa:\n", causes)

    def create_visualizations(self):
        if self.processed_data is None:
            self.clean_and_process_data()

        try:
            # Criar figura com subplots
            fig, axes = plt.subplots(2, 2, figsize=(15, 12))
            fig.suptitle('An√°lise de Inc√™ndios na Amaz√¥nia', fontsize=16, fontweight='bold')

            # Gr√°fico 1: N√∫mero de inc√™ndios por m√™s
            try:
                monthly_counts = self.processed_data['mes'].value_counts().sort_index()
                axes[0, 0].bar(monthly_counts.index, monthly_counts.values, color='orange', alpha=0.7)
                axes[0, 0].set_title('N√∫mero de Inc√™ndios por M√™s')
                axes[0, 0].set_xlabel('M√™s')
                axes[0, 0].set_ylabel('Quantidade')
                axes[0, 0].grid(True, alpha=0.3)
            except Exception as e:
                axes[0, 0].text(0.5, 0.5, f'Erro no gr√°fico 1:\n{str(e)[:50]}...',
                                transform=axes[0, 0].transAxes, ha='center', va='center')

            # Gr√°fico 2: Distribui√ß√£o por causa
            try:
                cause_counts = self.processed_data['causa'].value_counts()
                axes[0, 1].pie(cause_counts.values, labels=cause_counts.index, autopct='%1.1f%%', startangle=90)
                axes[0, 1].set_title('Distribui√ß√£o por Causa')
            except Exception as e:
                axes[0, 1].text(0.5, 0.5, f'Erro no gr√°fico 2:\n{str(e)[:50]}...',
                                transform=axes[0, 1].transAxes, ha='center', va='center')

            # Gr√°fico 3: √Årea queimada por estado
            try:
                state_area = self.processed_data.groupby('estado')['tamanho_ha'].sum().sort_values(ascending=False)
                axes[1, 0].barh(state_area.index, state_area.values, color='red', alpha=0.6)
                axes[1, 0].set_title('√Årea Total Queimada por Estado (ha)')
                axes[1, 0].set_xlabel('√Årea (hectares)')
            except Exception as e:
                axes[1, 0].text(0.5, 0.5, f'Erro no gr√°fico 3:\n{str(e)[:50]}...',
                                transform=axes[1, 0].transAxes, ha='center', va='center')

            # Gr√°fico 4: Evolu√ß√£o temporal
            try:
                temporal = self.processed_data.groupby(['ano', 'mes']).size().reset_index(name='count')
                # Criar data corretamente com dia = 1
                temporal['data'] = pd.to_datetime(temporal.assign(dia=1)[['ano', 'mes', 'dia']])
                axes[1, 1].plot(temporal['data'], temporal['count'], marker='o', linewidth=2, markersize=4)
                axes[1, 1].set_title('Evolu√ß√£o Temporal dos Inc√™ndios')
                axes[1, 1].set_xlabel('Data')
                axes[1, 1].set_ylabel('N√∫mero de Inc√™ndios')
                axes[1, 1].grid(True, alpha=0.3)

                # Rotacionar labels do eixo x para melhor legibilidade
                for tick in axes[1, 1].get_xticklabels():
                    tick.set_rotation(45)
            except Exception as e:
                # Se falhar, criar gr√°fico alternativo simples
                print(f"Aviso: Erro no gr√°fico temporal, criando vers√£o simplificada: {e}")
                yearly_counts = self.processed_data['ano'].value_counts().sort_index()
                axes[1, 1].bar(yearly_counts.index, yearly_counts.values, color='blue', alpha=0.6)
                axes[1, 1].set_title('Inc√™ndios por Ano')
                axes[1, 1].set_xlabel('Ano')
                axes[1, 1].set_ylabel('N√∫mero de Inc√™ndios')
                axes[1, 1].grid(True, alpha=0.3)

            plt.tight_layout()

            # Salvar o gr√°fico
            try:
                plt.savefig('incendios_visualizacao.png', dpi=300, bbox_inches='tight')
                print("‚úÖ Gr√°fico salvo como 'incendios_visualizacao.png'")
            except Exception as e:
                print(f"‚ö†Ô∏è  Erro ao salvar gr√°fico: {e}")

            # Limpar a figura da mem√≥ria
            plt.close()

        except Exception as e:
            print(f"‚ùå Erro geral na cria√ß√£o de visualiza√ß√µes: {e}")
            print("Continuando an√°lise sem gr√°ficos...")
            plt.close('all')  # Fechar todas as figuras

    def create_additional_analysis(self):
        """An√°lise adicional com estat√≠sticas mais detalhadas"""
        if self.processed_data is None:
            self.clean_and_process_data()

        print("\n" + "=" * 60)
        print("AN√ÅLISE DETALHADA ADICIONAL")
        print("=" * 60)

        # An√°lise por esta√ß√£o seca vs √∫mida
        season_analysis = self.processed_data.groupby('estacao_seca').agg({
            'tamanho_ha': ['count', 'sum', 'mean', 'median'],
            'data': 'count'
        }).round(2)

        print("\nüìä An√°lise por Esta√ß√£o:")
        print("Esta√ß√£o Seca (Maio-Outubro) vs √ömida (Novembro-Abril)")
        print(season_analysis)

        # Top 3 estados mais afetados
        top_states = self.processed_data.groupby('estado').agg({
            'tamanho_ha': ['count', 'sum', 'mean']
        }).round(2).sort_values(('tamanho_ha', 'sum'), ascending=False).head(3)

        print("\nüî• Top 3 Estados Mais Afetados:")
        print(top_states)

        # An√°lise de tamanho dos inc√™ndios
        size_distribution = self.processed_data['classificacao_tamanho'].value_counts()
        print("\nüìè Distribui√ß√£o por Tamanho:")
        for size, count in size_distribution.items():
            percentage = (count / len(self.processed_data)) * 100
            print(f"   {size}: {count} ({percentage:.1f}%)")

        # Estat√≠sticas gerais
        print(f"\nüìà Estat√≠sticas Gerais:")
        print(f"   Maior inc√™ndio: {self.processed_data['tamanho_ha'].max():.2f} ha")
        print(f"   Menor inc√™ndio: {self.processed_data['tamanho_ha'].min():.2f} ha")
        print(f"   M√©dia: {self.processed_data['tamanho_ha'].mean():.2f} ha")
        print(f"   Mediana: {self.processed_data['tamanho_ha'].median():.2f} ha")

    def generate_recommendations(self):
        print("\n" + "=" * 60)
        print("üéØ RECOMENDA√á√ïES ESTRAT√âGICAS")
        print("=" * 60)

        recommendations = [
            "üî• PREVEN√á√ÉO: Intensificar monitoramento na esta√ß√£o seca (maio-outubro)",
            "üõ°Ô∏è  FISCALIZA√á√ÉO: Aumentar presen√ßa em Par√°, Amazonas e Rond√¥nia",
            "üì° TECNOLOGIA: Implementar sistemas de alerta em tempo real",
            "üë• EDUCA√á√ÉO: Campanhas focadas na redu√ß√£o de queimadas humanas (70% dos casos)",
            "üåø RESTAURA√á√ÉO: Programas de recupera√ß√£o de √°reas degradadas",
            "ü§ù PARCERIAS: Coopera√ß√£o entre estados e √≥rg√£os federais",
            "üí∞ RECURSOS: Destina√ß√£o de verbas espec√≠ficas para preven√ß√£o",
            "üìä DADOS: Melhorar coleta e an√°lise de dados em tempo real"
        ]

        for i, rec in enumerate(recommendations, 1):
            print(f"{i:2d}. {rec}")

    def export_summary_report(self):
        """Gerar relat√≥rio resumido em texto"""
        if self.processed_data is None:
            self.clean_and_process_data()

        report_filename = f"relatorio_incendios_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"

        with open(report_filename, 'w', encoding='utf-8') as f:
            f.write("RELAT√ìRIO DE AN√ÅLISE DE INC√äNDIOS NA AMAZ√îNIA\n")
            f.write("=" * 50 + "\n")
            f.write(f"Gerado em: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\n\n")

            f.write(f"RESUMO EXECUTIVO:\n")
            f.write(f"- Total de inc√™ndios analisados: {len(self.processed_data)}\n")
            f.write(f"- √Årea total queimada: {self.processed_data['tamanho_ha'].sum():.2f} hectares\n")
            f.write(f"- Per√≠odo analisado: 2021-2024\n\n")

            # Adicionar estat√≠sticas por ano
            yearly_stats = self.processed_data.groupby('ano').agg({
                'tamanho_ha': ['count', 'sum']
            }).round(2)

            f.write("ESTAT√çSTICAS ANUAIS:\n")
            for year in yearly_stats.index:
                count = yearly_stats.loc[year, ('tamanho_ha', 'count')]
                area = yearly_stats.loc[year, ('tamanho_ha', 'sum')]
                f.write(f"  {year}: {count} inc√™ndios, {area:.2f} ha queimados\n")

        print(f"üìÑ Relat√≥rio exportado como: {report_filename}")

    def run_full_analysis(self):
        """Executar an√°lise completa"""
        print("üî• SISTEMA DE MONITORAMENTO DE QUEIMADAS NA AMAZ√îNIA")
        print("=" * 60)

        try:
            self.generate_sample_data()
            self.clean_and_process_data()
            self.descriptive_analysis()
            self.create_additional_analysis()
            self.create_visualizations()
            self.export_summary_report()
            self.generate_recommendations()

            print("\n‚úÖ An√°lise completa executada com sucesso!")

        except Exception as e:
            print(f"‚ùå Erro durante a an√°lise: {e}")
            print("Verifique as depend√™ncias e tente novamente.")


# Execu√ß√£o
if __name__ == "__main__":
    analyzer = AmazonFireAnalyzer()
    analyzer.run_full_analysis()

    # Simular dados de status atual (como seria retornado pela API)
    print("\n" + "=" * 60)
    print("üìä SIMULA√á√ÉO - STATUS ATUAL DO SISTEMA")
    print("=" * 60)

    current_status = {
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "status_amazonia": "‚ö†Ô∏è  ALERTA M√âDIO",
        "incendios_24h": 47,
        "area_afetada_24h": "1,247 hectares",
        "risco_nivel": "M√©dio-Alto",
        "estados_criticos": ["Par√°", "Amazonas", "Rond√¥nia"],
        "previsao_proximas_24h": "Condi√ß√µes favor√°veis para novos focos"
    }

    print(f"üïí √öltima atualiza√ß√£o: {current_status['timestamp']}")
    print(f"üìä Status atual: {current_status['status_amazonia']}")
    print(f"üî• Inc√™ndios (24h): {current_status['incendios_24h']}")
    print(f"üå≥ √Årea afetada (24h): {current_status['area_afetada_24h']}")
    print(f"‚ö†Ô∏è  N√≠vel de risco: {current_status['risco_nivel']}")
    print(f"üó∫Ô∏è  Estados em situa√ß√£o cr√≠tica: {', '.join(current_status['estados_criticos'])}")
    print(f"üîÆ Previs√£o: {current_status['previsao_proximas_24h']}")

    print("\n" + "=" * 60)
    print("üéØ SISTEMA PRONTO PARA MONITORAMENTO CONT√çNUO")
    print("=" * 60)